#### 代理池的设计

1，代理池的工作流程

- 代理ip采集模块：抓取代理ip->校验代理ip可用性->如果可用->数据库（代理池）
- 检验模块：读取数据库的代理ip->校验代理ip可用性->更新或删除代理ip
- 代理api模块：从数据库中获取高可用代理ip给爬虫使用

2，五大核心模块

- 代理ip采集模块——采集代理ip，把可用代理ip入库
- 校验模块——检测代理可用性：响应速度、协议类型、匿名程度
- 数据库模块——对代理ip进行增删改查的操作
- 检测模块——获取数据库的代理ip进行处理，保证代理ip的可用性
- api模块——提供爬虫或高可用代理ip和指定代理ip不可用域名的接口

3，其他模块

- 数据模型：用于封装代理ip信息
- main.py：启动的统一入口
- utils工具模块
  - http.py：提供随机的请求头
  - log.py：日志模块，输出记录日志

- settings：配置文件，用于对项目进行配置

#### 代理池思路

- 先实现不依赖其他模块的基础模块，在实现具体功能模块

#### 具体实现步骤

1，定义代理ip的数据模型类--domain.py。

- 定义Proxy类，继承object
- 实现__init__方法，负责初始化。
- 在配置文件中定义MAX_SCORE = 50，表示代理ip的默认最高分数
- 提供str方法，返回数据字符串

2，实现代理池的工具模块，日志模块和http模块

- 日志模块：输出日志--log.py
  - 拷贝代码
  - 把日志相关信息放到配置文件中
  - 修改日志代码，使用配置文件的配置信息
- http模块：提供请求头--http.py
  - 准备列表
  - 实现一个方法，获取随机的一个请求头

3，代理池的校验模块，对代理ip进行速度、匿名程度及支持的协议类型进行检查--httpbin_validate.py

- 检查代理ip速度和匿名程度
  - 速度：从发送请求到获取响应的时间间隔
  - 匿名程度检查：对http://httpbin.org/get或者https://httpbin.org/get发送请求，获取响应数据

- 检查代理ip协议类型

4，代理池的数据库模块，应用于对proxies集合进行数据库的相关操作--mongo_pool.py

- 实现数据库模块的增删改查
  - 在init中建立数据连接，获取操作的集合，在del方法中关闭数据库连接
  - 提供基础的增删改查功能
  - 提供代理api模块使用的功能
- mongodb命令：
  - 显示所有的数据库：show dbs
  - 增加数据库：use runoob
  - 删除数据库：在库里输入db.dropDatabase()
  - 显示数据表：show collections
  - 显示表内容：db.表名.find()
- 实现数据库模块的给代理API模块使用的功能

5，实现代理池的爬虫模块

- 代理网站
  - 66免费代理：http://www.66ip.cn/index.html
  - proxylistplus代理：https://list.proxylistplus.com/Fresh-HTTP-Proxy-List-1
  - 云代理：http://www.ip3366.net/free/
  - x西拉代理：http://www.xiladaili.com/http/366/
  - 快代理：https://www.kuaidaili.com/free/
- 高可用全球免费代理IP库：https://ip.jiangxianli.com/?page=1
  - 31代理：http://31f.cn/
  - 89免费代理：https://www.89ip.cn/index.html
  - 齐云代理：https://www.7yip.cn/free/
  
- 爬虫模块的设计思路
  - 通用爬虫：xpath--base_spider.py
    - 定义类
    - 提供三个成员变量
    - 提供初始化方法
    - 对外提供获取代理ip的方法
  - 具体爬虫：继承通用爬虫实现--proxy_spiders.py
  - 爬虫运行模块：根据配置文件信息，启动爬虫，抓取代理ip进行检测，若可用，就存储到数据库中--run_spiders.py
    - 在run_spiders.py文件中创建一个runspider类
    - 提供一个运行爬虫的run方法
      - 获取爬虫列表
      - 遍历列表，获取对象，遍历get_proxies方法，获取ip
      - 检测代理ip

6，使用异步来执行每一个爬虫任务

- 在init方法中创建协程池队象
- 把处理一个代理爬虫的代码抽到一个方法
- 使用异步执行此方法
- 在循环外，调用协程的join方法，让当前线程等待协程任务的完成

7，使用schedule模块，实现每个一定的时间，执行一次爬虫任务

- 定义一个start的类方法
- 创建当前类的对象，调用run方法
- 使用schedule模块，每个一定时间，执行当前对象的run方法

8，实现代理池的检测模块：检查代理ip的可用性--proxy_test.py

- 在proxy_test.py中，创建ProxyTest类
- 提供一个run方法，用于处理检测代理IP的核心逻辑
  - 1）从数据库中获取代理IP
  - 2）遍历代理IP列表
  - 3）检查代理IP可用性
    - 如果不可用，该代理-1，若分数变为0，就从数据库中删除该ip，否则更新该代理ip
    - 如果可用，则回复该代理ip的分数，更新到数据库中

- 为了提高检查速度，使用异步来执行检测任务
  - 把要检测的代理IP放到队列中
  - 把检查一个代理可用性的代码抽取到一个方法中，从队列中获取IP，进行检查，检查完毕调取队列中的task_done方法
  - 通过异步回调，使用死循环不断执行此方法
  - 开启多个异步任务，来处理代理IP的检测，通过配置文件指定异步数量

- 使用schedule模块，每个一段时间，执行一次检测任务
  - 定义一个start的类方法
  - 创建当前类的对象，调用run方法
  - 使用schedule模块，每个一定时间，执行当前对象的run方法

9，实现代理池的api模块——为爬虫提供高可用代理的服务接口--proxy_api.py

- 实现根据协议类型和域名，提供随机获取高可用代理ip的服务
- 实现根据协议类型和域名，提供获取多个高可用代理ip的服务
- 实现给指定ip追加不可用域名的服务
- 实现
  - 在proxy_api.py模块中创建一个ProxyApi类
  - 实现初始方法
    - 初始一个Flask的web服务器
    - 实现根据协议类型和域名，提供随机获取高可用代理ip的服务
      - 可通过protocol和domain参数对ip进行过滤
      - protocol：当前请求的协议类型
      - domain：当前请求域名
    - 实现根据协议类型和域名，提供获取多个高可用代理ip的服务
      - 可用通过protocol和domain参数对ip进行过滤
    - 实现给指定ip追加不可用域名的服务
      - 如果在获取ip的时候，有指定域名参数，将不再获取该ip，从而进一步提高代理ip的可用性
    - 实现run方法，用于启动flask的web服务
    - 实现start类方法，用于通过类名启动服务

10，实现代理池的启动入口——把启动爬虫、检测代理ip、启动web服务统一到一起--main.py

- 思路：开启三个进程，分别用于启动爬虫、检测代理ip、web服务
- 步骤：
  - 定义一个run方法用于启动代理池
    - 定义一个列表，用于存储要启动的进程
    - 创建启动爬虫的进程，添加到列表中
    - 创建启动检测代理ip的进程，添加到列表中
    - 创建启动web服务的进程，添加到列表中
    - 遍历进程列表，启动所有进程
    - 遍历进程列表，让主进程等待子进程完成

- 在if __name__ == '__main__':中调用run方法